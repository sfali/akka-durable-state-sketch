akka.actor.allow-java-serialization = true

delivery-date-service {
  projections-slice-count = 4
  projections.topic = "delivery-date-events"
}

akka {
  loglevel = INFO

  actor {
    provider = "cluster"
    debug {
      receive = on
      lifecycle = on
    }
  }

  remote {
    artery {
      transport = tcp
      canonical.hostname = "127.0.0.1"
      canonical.port = 25520
    }
  }

  cluster {
    seed-nodes = [
      "akka://delivery-date-app@127.0.0.1:25520",
    ]
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
  }

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  persistence {
    journal.plugin = "akka.persistence.r2dbc.journal"
    snapshot-store.plugin = "akka.persistence.r2dbc.snapshot"
    state.plugin = "akka.persistence.r2dbc.state"

    r2dbc.connection-factory = ${akka.persistence.r2dbc.postgres}
    r2dbc.connection-factory {
      host = "localhost"
      database = "testdb"
      user = "postgres"
      password = "password"
    }
  }

  projection.r2dbc {
    offset-store {
      offset-table = ""
    }
  }

  kafka.consumer {
    kafka-clients {
      bootstrap.servers = "locahost:9092"
    }
  }

  kafka.producer {
    kafka-clients {
      bootstrap.servers = "locahost:9092"
    }
  }
}